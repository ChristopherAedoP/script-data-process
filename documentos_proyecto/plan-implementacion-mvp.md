# Plan de Implementaci√≥n Ejecutable - Chatbot Pol√≠tico MVP

**Proyecto**: Sistema de consulta inteligente sobre programas presidenciales chilenos  
**Stack**: Next.js 14 + Convex + assistant-ui + OpenAI  
**Documento creado**: Agosto 2025  

---

## Resumen Ejecutivo

### ‚úÖ Validaci√≥n del PDR
- **Stack t√©cnico s√≥lido**: Convex + assistant-ui son production-ready
- **Riesgo principal identificado**: Procesamiento de PDFs con mitigaciones claras
- **Scope claro**: Solo consultas y comparaciones, sin features extras

### üéØ Approach Estrat√©gico
- **Week 1 es cr√≠tica**: Validar procesamiento PDFs con 1-2 PDFs antes de escalar a 7
- **Validaci√≥n iterativa**: Checkpoint en cada paso antes de continuar
- **Go/No-Go decisions**: Criterios claros para determinar si continuar o ajustar

### üìä Success Metrics MVP
- Procesar 7+ programas presidenciales exitosamente
- >85% precisi√≥n en respuestas (validadas manualmente)
- Comparaciones multi-candidato funcionales
- Interfaz usable para cualquier persona (incluye abuelas)

---

## Estructura Completa del Proyecto

```
chatbot-politico/
‚îú‚îÄ‚îÄ app/                          # Next.js 14 app directory
‚îÇ   ‚îú‚îÄ‚îÄ layout.tsx                # Root layout con providers
‚îÇ   ‚îú‚îÄ‚îÄ page.tsx                  # Chat interface principal
‚îÇ   ‚îú‚îÄ‚îÄ globals.css               # Estilos globales
‚îÇ   ‚îî‚îÄ‚îÄ api/                      # API routes (si necesario)
‚îÇ       ‚îî‚îÄ‚îÄ health/
‚îÇ           ‚îî‚îÄ‚îÄ route.ts          # Health check endpoint
‚îú‚îÄ‚îÄ convex/                       # Convex backend completo
‚îÇ   ‚îú‚îÄ‚îÄ _generated/              # Auto-generados por Convex
‚îÇ   ‚îú‚îÄ‚îÄ schema.ts                # Database schema con vector index
‚îÇ   ‚îú‚îÄ‚îÄ queries.ts               # Vector search functions
‚îÇ   ‚îú‚îÄ‚îÄ mutations.ts             # Data ingestion endpoints
‚îÇ   ‚îú‚îÄ‚îÄ aiChat.ts                # OpenAI integration
‚îÇ   ‚îî‚îÄ‚îÄ lib/                     # Utilidades del backend
‚îÇ       ‚îú‚îÄ‚îÄ openai.ts           # OpenAI client config
‚îÇ       ‚îî‚îÄ‚îÄ utils.ts            # Helper functions
‚îú‚îÄ‚îÄ components/                   # UI components
‚îÇ   ‚îú‚îÄ‚îÄ ChatInterface.tsx        # Componente principal del chat
‚îÇ   ‚îú‚îÄ‚îÄ MessageBubble.tsx        # Componente individual de mensaje
‚îÇ   ‚îú‚îÄ‚îÄ SourceCitation.tsx       # Componente para citas
‚îÇ   ‚îî‚îÄ‚îÄ ui/                      # shadcn/ui components
‚îÇ       ‚îú‚îÄ‚îÄ button.tsx
‚îÇ       ‚îú‚îÄ‚îÄ input.tsx
‚îÇ       ‚îú‚îÄ‚îÄ card.tsx
‚îÇ       ‚îî‚îÄ‚îÄ loading.tsx
‚îú‚îÄ‚îÄ lib/                         # Frontend utilities
‚îÇ   ‚îú‚îÄ‚îÄ utils.ts                 # Utilidades generales
‚îÇ   ‚îú‚îÄ‚îÄ constants.ts             # Constantes de la app
‚îÇ   ‚îî‚îÄ‚îÄ types.ts                 # TypeScript types
‚îú‚îÄ‚îÄ scripts/                     # PDF processing pipeline
‚îÇ   ‚îú‚îÄ‚îÄ process_pdfs.py          # Script principal de procesamiento
‚îÇ   ‚îú‚îÄ‚îÄ test_extraction.py       # Testing de extracci√≥n
‚îÇ   ‚îú‚îÄ‚îÄ test_embeddings.py       # Testing de embeddings
‚îÇ   ‚îú‚îÄ‚îÄ test_upload.py           # Testing de upload a Convex
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt         # Python dependencies
‚îÇ   ‚îú‚îÄ‚îÄ config.py               # Configuraci√≥n del script
‚îÇ   ‚îî‚îÄ‚îÄ pdfs/                   # Raw PDFs folder
‚îÇ       ‚îú‚îÄ‚îÄ kast_programa.pdf
‚îÇ       ‚îú‚îÄ‚îÄ jara_programa.pdf
‚îÇ       ‚îú‚îÄ‚îÄ sichel_programa.pdf
‚îÇ       ‚îú‚îÄ‚îÄ boric_programa.pdf
‚îÇ       ‚îú‚îÄ‚îÄ parisi_programa.pdf
‚îÇ       ‚îú‚îÄ‚îÄ art√©s_programa.pdf
‚îÇ       ‚îî‚îÄ‚îÄ provoste_programa.pdf
‚îú‚îÄ‚îÄ tests/                       # Testing suite
‚îÇ   ‚îú‚îÄ‚îÄ validate_week1.sh       # Week 1 validation
‚îÇ   ‚îú‚îÄ‚îÄ validate_week2.sh       # Week 2 validation
‚îÇ   ‚îú‚îÄ‚îÄ health_check.sh         # Production health check
‚îÇ   ‚îî‚îÄ‚îÄ e2e/                    # End-to-end tests
‚îÇ       ‚îî‚îÄ‚îÄ chat.spec.ts
‚îú‚îÄ‚îÄ docs/                        # Documentaci√≥n
‚îÇ   ‚îú‚îÄ‚îÄ plan-implementacion-mvp.md  # Este documento
‚îÇ   ‚îú‚îÄ‚îÄ pdr-chatbot-politico.md     # PDR original
‚îÇ   ‚îî‚îÄ‚îÄ deployment-guide.md         # Gu√≠a de deployment
‚îú‚îÄ‚îÄ .env.local.example          # Template de variables de entorno
‚îú‚îÄ‚îÄ package.json                # Dependencies y scripts
‚îú‚îÄ‚îÄ convex.json                 # Configuraci√≥n de Convex
‚îú‚îÄ‚îÄ next.config.js              # Configuraci√≥n de Next.js
‚îú‚îÄ‚îÄ tailwind.config.js          # Configuraci√≥n de Tailwind
‚îú‚îÄ‚îÄ tsconfig.json               # TypeScript config
‚îî‚îÄ‚îÄ README.md                   # Instrucciones b√°sicas del proyecto
```

---

Esto deja **Python solo para la ingesta** y **Convex como backend persistente + API**.
El frontend ya no depende de tu script, sino solo de Convex.

---


* Hacer **todo el pipeline en Python localmente** (OCR ‚Üí chunks ‚Üí embeddings ‚Üí index),
* vs. usar Convex como backend y **subir ah√≠ los datos ya procesados**.

D√©jame ordenar el an√°lisis:

---

##  ¬øConvex puede recibir embeddings ‚Äúya hechos‚Äù?

S√≠ . Convex no genera embeddings por s√≠ mismo. Lo que hace es:

* Guardar tus documentos/chunks en su base,
* Guardar los **vectores de embeddings** en un campo especial,
* Crear un `vectorIndex` sobre esos embeddings,
* Permitir b√∫squedas sem√°nticas (`vectorSearch`) con filtros (por `doc_id`, `tema`, etc).

 Eso significa que t√∫ **puedes crear los embeddings en Python** (como ya haces con OpenAI o con un modelo local tipo `bge-m3`) y luego subirlos a Convex v√≠a **API o SDK**.

---

##  SDKs de Convex

Convex est√° pensado para **TypeScript / JavaScript** como primera clase.

* **SDK oficial**: [`convex/browser`](https://docs.convex.dev/using/quickstart) y [`convex/react`](https://docs.convex.dev/react).
* Para Python: **no hay SDK oficial directo**.

  * Pero puedes hablar con la API de Convex (es HTTP JSON), o
  * Hacer un micro-backend en Node que reciba tus datos desde Python y los inserte en Convex.

En resumen:

* **Python ‚Üí embeddings/chunks ‚Üí POST JSON ‚Üí Convex API (TS)**.
* Luego tu frontend web consulta a Convex directamente.

---

 Te hago un diagrama de alto nivel con las piezas y el flujo.

---

## üèóÔ∏è Arquitectura propuesta

```
                ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                ‚îÇ        Usuario          ‚îÇ
                ‚îÇ  (Chat Web / Frontend)  ‚îÇ
                ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚îÇ
                            ‚ñº
                 ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                 ‚îÇ   Frontend (React) ‚îÇ
                 ‚îÇ   o Cliente Web    ‚îÇ
                 ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                             ‚îÇ pregunta
                             ‚ñº
                 ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                 ‚îÇ      Convex API    ‚îÇ
                 ‚îÇ (actions, queries) ‚îÇ
                 ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                             ‚îÇ
          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
          ‚îÇ                  ‚îÇ                  ‚îÇ
          ‚ñº                  ‚ñº                  ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Base de Chunks    ‚îÇ ‚îÇ Vector Index      ‚îÇ ‚îÇ Funci√≥n embeddings ‚îÇ
‚îÇ (texto, doc_id,   ‚îÇ ‚îÇ (sobre embeddings ‚îÇ ‚îÇ (OpenAI o local)   ‚îÇ
‚îÇ page, metadata)   ‚îÇ ‚îÇ de cada chunk)    ‚îÇ ‚îÇ para preguntas)    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

```

---

## üì• Ingesta de documentos (hecho en Python)

```
PDFs (programas pol√≠ticos)
       ‚îÇ
       ‚ñº
 ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
 ‚îÇ Pipeline Py   ‚îÇ
 ‚îÇ OCR + Limpieza‚îÇ
 ‚îÇ Chunking      ‚îÇ
 ‚îÇ Embeddings    ‚îÇ
 ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚îÇ (JSON con chunks+embeddings)
        ‚ñº
 ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
 ‚îÇ   Convex Action   ‚îÇ
 ‚îÇ  (insert chunks)  ‚îÇ
 ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üîÑ Consulta del usuario (chat)

1. Usuario pregunta en el frontend.
2. Convex recibe la pregunta:

   * Genera embedding de la pregunta.
   * Busca en el **vector index**.
   * Devuelve los chunks m√°s relevantes.
3. Esos chunks + la pregunta se mandan al **modelo de lenguaje (chat)**.
4. El modelo responde con texto + referencias.
5. Respuesta vuelve al frontend.

---



## ‚öôÔ∏è Flujo recomendado para tu MVP

1. **Ingesta en Python** (lo que ya tienes):

   * Abrir PDF ‚Üí OCR si hace falta ‚Üí limpieza ‚Üí chunking ‚Üí generar embeddings.
   * Obtienes:

     ```json
     {
       "doc_id": "kast",
       "page": 34,
       "text": "El programa propone un sistema mixto de pensiones...",
       "embedding": [0.123, -0.045, ...]
     }
     ```

2. **Carga a Convex**

   * Llamas a un endpoint/action en Convex que inserta esos objetos en la tabla `chunks`.
   * Cada fila: `doc_id`, `page`, `text`, `embedding`.
   * Convex crea un `vectorIndex` sobre `embedding`.

3. **Consulta desde frontend web (chat)**

   * Usuario pregunta ‚Üí Convex action genera embedding de la pregunta (puede ser OpenAI o local en el servidor).
   * Convex hace `vectorSearch` y devuelve los top-K chunks.
   * Frontend pasa esos chunks + pregunta al modelo de lenguaje (chat).

---

## üìù Respuesta a tu duda

* **Convex NO analiza chunks por s√≠ mismo** ‚Üí necesita que t√∫ le subas los embeddings listos.
* **S√≠ puedes procesar todo en Python como ahora** y luego subir chunks + embeddings a Convex.
* **Consumo web/chat**: lo har√≠as desde Convex (con vectorSearch) y/o desde tu backend (que a su vez consulta Convex).

---

üëâ En otras palabras:

* **Python** queda como tu **pipeline de ingesta** (ETL de PDFs ‚Üí embeddings).
* **Convex** queda como tu **almac√©n de chunks + embeddings** y la API que tu chat va a consumir.

---

¬øQuieres que te dibuje un **diagrama del flujo arquitect√≥nico** con estos pasos (Python ‚Üí Convex ‚Üí Chat Web), para que quede claro c√≥mo encajan todas las piezas?


## Plan Semanal Detallado

## D√≠a 1: Python Processing Setup
**Objetivos**: Entorno Python listo, test con 1 PDF  
**Prioridad**: üî• CR√çTICO  
**Usar como base**: `rag_pdf_kit/rag_pdf_kit.py`
### Tareas Espec√≠ficas
1. **Setup Python environment**
   ```bash
   cd scripts
   python -m venv venv
   source venv/bin/activate  # Windows: venv\Scripts\activate
   ```

2. **Crear `scripts/requirements.txt`**
   ```
   pymupdf4llm==0.0.9
   openai==1.12.0  
   python-dotenv==1.0.0
   requests==2.31.0
   tiktoken==0.5.2
   numpy==1.24.3
   ```

3. **Instalar dependencies**
   ```bash
   pip install -r requirements.txt
   ```

4. **Descargar 1 PDF de prueba**
   - Buscar programa presidencial de Kast 2021-2022
   - Guardar como `scripts/pdfs/kast_programa.pdf`
   - Verificar que es legible (abrir manualmente)

5. **Crear `scripts/config.py`**
   ```python
   import os
   from dotenv import load_dotenv
   
   load_dotenv()
   
   OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
   CONVEX_URL = os.getenv("CONVEX_URL") 
   CHUNK_SIZE = 1000  # tokens
   CHUNK_OVERLAP = 200  # tokens
   EMBEDDING_MODEL = "text-embedding-3-small"
   ```

6. **Crear `scripts/process_pdfs.py` b√°sico**
   ```python
   import pymupdf4llm
   import openai
   import tiktoken
   from config import *
   
   def extract_text_from_pdf(pdf_path):
       """Extract text maintaining structure"""
       md_text = pymupdf4llm.to_markdown(pdf_path)
       return md_text
   
   def chunk_text(text, candidate_name):
       """Split text into chunks with metadata"""
       # Implementar chunking b√°sico
       chunks = []
       # ... l√≥gica de chunking
       return chunks
   
   def test_single_pdf():
       pdf_path = "pdfs/kast_programa.pdf"
       print(f"Processing {pdf_path}...")
       
       # Extract
       text = extract_text_from_pdf(pdf_path)
       print(f"Extracted {len(text)} characters")
       
       # Chunk
       chunks = chunk_text(text, "Jos√© Antonio Kast")
       print(f"Generated {len(chunks)} chunks")
       
       return chunks
   
   if __name__ == "__main__":
       test_single_pdf()
   ```

7. **Test extracci√≥n completa**
   ```bash
   python process_pdfs.py
   ```

### ‚úÖ Checkpoint de Validaci√≥n
- ‚úÖ pymupdf4llm extrae texto limpio del PDF (sin caracteres raros)
- ‚úÖ Chunking genera 20-50 chunks coherentes
- ‚úÖ Cada chunk tiene entre 800-1200 tokens
- ‚úÖ Texto extra√≠do es >80% coherente al verificar manualmente

### ‚ùå Criterios de Stop
- PDF no se puede procesar (archivo corrupto)
- Texto extra√≠do es <50% coherente
- Chunking genera <10 chunks o chunks sin sentido

**Si extracci√≥n <80% coherente ‚Üí STOP y cambiar a OCR con Tesseract**
---

# SEMANA 2: Procesamiento de Documentos (CR√çTICO)

## D√≠a 2: Setup Foundation
**Objetivos**: Convex + Next.js funcionando, schema deployed  
**Tiempo estimado**: 4 horas  
**Prioridad**: üî• CR√çTICO  

### Tareas Espec√≠ficas
1. **Crear proyecto Next.js**
   ```bash
   npx create-next-app@latest chatbot-politico --typescript --tailwind --app
   cd chatbot-politico
   ```

2. **Setup Convex**
   ```bash
   npx convex init
   # Seguir wizard de configuraci√≥n
   ```

3. **Crear schema en `convex/schema.ts`**
   ```typescript
   import { defineSchema, defineTable } from "convex/server";
   import { v } from "convex/values";
   
   export default defineSchema({
     chunks: defineTable({
       candidate: v.string(),
       section: v.string(),
       subsection: v.optional(v.string()),
       content: v.string(),
       page_number: v.number(),
       token_count: v.number(),
       keywords: v.array(v.string()),
       importance_score: v.number(),
       document_title: v.string(),
       embedding: v.array(v.number()), // 1536 dimensions
     }).vectorIndex("by_content", {
       vectorField: "embedding",
       dimensions: 1536,
       filterFields: ["candidate", "section"]
     }),
   
     conversations: defineTable({
       query: v.string(),
       response: v.string(),
       sources: v.array(v.string()),
       response_time_ms: v.number(),
       created_at: v.number(),
     })
   });
   ```

4. **Deploy schema inicial**
   ```bash
   npx convex deploy
   ```

5. **Verificar en Convex Dashboard**
   - Abrir dashboard desde terminal output
   - Confirmar schema deployed
   - Verificar vector index creado

### ‚úÖ Checkpoint de Validaci√≥n
- ‚úÖ Convex dashboard muestra proyecto activo
- ‚úÖ Schema deployed sin errores  
- ‚úÖ Vector index "by_content" visible en dashboard
- ‚úÖ Next.js app arranca en localhost:3000

### ‚ùå Criterios de Stop
- Schema deployment falla
- Vector index no se crea autom√°ticamente  
- Errores de conexi√≥n a Convex

**Si falla ‚Üí STOP y resolver antes de continuar**


---

## D√≠a 3: Convex Integration + Upload
**Objetivos**: Script completo sube chunks a Convex  
**Tiempo estimado**: 8 horas  
**Prioridad**: üî• CR√çTICO  

### Tareas Espec√≠ficas
1. **Completar `scripts/process_pdfs.py` con embeddings**
   ```python
   def generate_embeddings(chunks):
       """Generate OpenAI embeddings for chunks"""
       client = openai.OpenAI(api_key=OPENAI_API_KEY)
       
       for chunk in chunks:
           response = client.embeddings.create(
               model=EMBEDDING_MODEL,
               input=chunk["content"]
           )
           chunk["embedding"] = response.data[0].embedding
       
       return chunks
   ```

2. **Crear `convex/mutations.ts`**
   ```typescript
   import { mutation } from "./_generated/server";
   import { v } from "convex/values";
   
   export const insertChunk = mutation({
     args: {
       candidate: v.string(),
       section: v.string(),
       content: v.string(),
       page_number: v.number(),
       token_count: v.number(),
       keywords: v.array(v.string()),
       importance_score: v.number(),
       document_title: v.string(),
       embedding: v.array(v.number()),
     },
     handler: async (ctx, args) => {
       return await ctx.db.insert("chunks", args);
     },
   });
   ```

3. **HTTP Upload en `process_pdfs.py`**
   ```python
   import requests
   
   def upload_to_convex(chunks):
       """Upload chunks to Convex via HTTP"""
       for chunk in chunks:
           response = requests.post(
               f"{CONVEX_URL}/api/insertChunk",
               json=chunk
           )
           if response.status_code != 200:
               print(f"Failed to upload chunk: {response.text}")
           else:
               print(f"Uploaded chunk successfully")
   ```

4. **Test upload completo**
   ```bash
   python process_pdfs.py
   ```

5. **Verificar en Convex Dashboard**
   - Ver chunks en tabla "chunks"
   - Verificar embeddings est√°n poblados
   - Verificar metadata completa

### ‚úÖ Checkpoint de Validaci√≥n
- ‚úÖ 20-50 chunks aparecen en Convex database
- ‚úÖ Cada chunk tiene embedding de 1536 dimensiones
- ‚úÖ Metadata completa (candidato, secci√≥n, p√°gina)
- ‚úÖ No errores en upload process

### ‚ùå Criterios de Stop
- Upload falla consistentemente
- Embeddings no se generan (error de OpenAI API)
- Chunks aparecen sin metadata

**Si upload falla ‚Üí STOP y debuggear HTTP connection**

---

## D√≠a 4: Scale to All PDFs  
**Objetivos**: Procesar los 7 PDFs completos  
**Tiempo estimado**: 6 horas  
**Prioridad**: üî• CR√çTICO  

### Tareas Espec√≠ficas
1. **Descargar restantes 6 PDFs**
   - Gabriel Boric (Apruebo Dignidad 2021)
   - Sebasti√°n Sichel (Chile Podemos M√°s 2021)  
   - Franco Parisi (Partido de la Gente 2021)
   - Marco Enr√≠quez-Ominami (PRO 2021)
   - Yasna Provoste (Nuevo Pacto Social 2021)
   - Eduardo Art√©s (Uni√≥n Patri√≥tica 2021)
   
   Guardar en `scripts/pdfs/` con nombres consistentes

2. **Actualizar `process_pdfs.py` para batch processing**
   ```python
   def process_all_pdfs():
       pdf_configs = [
           {"file": "kast_programa.pdf", "candidate": "Jos√© Antonio Kast"},
           {"file": "boric_programa.pdf", "candidate": "Gabriel Boric"},
           {"file": "sichel_programa.pdf", "candidate": "Sebasti√°n Sichel"},
           # ... resto de candidatos
       ]
       
       for config in pdf_configs:
           try:
               print(f"Processing {config['candidate']}...")
               process_single_pdf(config["file"], config["candidate"])
           except Exception as e:
               print(f"ERROR processing {config['candidate']}: {e}")
               # Log pero continuar con otros PDFs
   ```

3. **Ejecutar procesamiento completo**
   ```bash
   python process_pdfs.py --batch
   ```

4. **Monitorear proceso**
   - Tracking de progreso por candidato
   - Log de errores espec√≠ficos  
   - Tiempo estimado de completion

5. **Validar resultados en Convex**
   - Verificar ~500-1000 chunks totales
   - Confirmar distribuci√≥n por candidato
   - Test queries b√°sicas

### ‚úÖ Checkpoint de Validaci√≥n
- ‚úÖ Al menos 5/7 PDFs procesados exitosamente
- ‚úÖ Total chunks entre 500-1000 en database
- ‚úÖ Distribuci√≥n razonable por candidato (50-150 chunks c/u)
- ‚úÖ No m√°s de 2 PDFs fallaron completamente

### ‚ùå Criterios de Stop
- <5 PDFs procesados exitosamente
- <300 chunks totales en database
- Errores sistem√°ticos en embeddings

**Si <5 PDFs procesados ‚Üí STOP y resolver extracci√≥n**

---

## D√≠a 5: Query Validation
**Objetivos**: Validar calidad de b√∫squedas  
**Tiempo estimado**: 4 horas  
**Prioridad**: üî• CR√çTICO  

### Tareas Espec√≠ficas
1. **Crear `convex/queries.ts`**
   ```typescript
   import { query } from "./_generated/server";
   import { v } from "convex/values";
   
   export const vectorSearch = query({
     args: {
       searchText: v.string(),
       candidate: v.optional(v.string()),
       limit: v.optional(v.number()),
     },
     handler: async (ctx, args) => {
       // Implementar vector search b√°sico
       const results = await ctx.vectorSearch("chunks", "by_content", {
         vector: await getEmbedding(args.searchText),
         limit: args.limit ?? 5,
         filter: args.candidate ? (q) => q.eq("candidate", args.candidate) : undefined,
       });
       
       return results;
     },
   });
   ```

2. **Test 20+ consultas desde Convex Dashboard**
   Queries de prueba:
   - "¬øQu√© propone Kast sobre pensiones?"
   - "Pol√≠ticas econ√≥micas de Boric"  
   - "Propuestas de seguridad ciudadana"
   - "Educaci√≥n superior gratuita"
   - "Impuestos y reforma tributaria"
   - "Salud p√∫blica y privada"
   - "Pol√≠tica exterior con pa√≠ses vecinos"
   - "Medio ambiente y cambio clim√°tico"
   - "Derechos de la mujer"
   - "Pueblos originarios"

3. **Validar precision manualmente**
   - Cada query debe retornar chunks relevantes
   - Verificar que chunks pertenecen al candidato correcto
   - Confirmar que contenido es pertinente a la consulta

4. **Ajustar filtros si necesario**
   - Por candidato espec√≠fico
   - Por secci√≥n del programa
   - Por relevance score

5. **Test queries multi-candidato**
   - B√∫squedas que deber√≠an retornar m√∫ltiples candidatos
   - Verificar que no hay bias hacia alg√∫n candidato

### ‚úÖ Go/No-Go Decision Point
- ‚úÖ Vector search >80% precision en test queries
- ‚úÖ Multi-candidate searches funcionan correctamente  
- ‚úÖ Response time <2s para b√∫squedas
- ‚úÖ No bias sistem√°tico hacia alg√∫n candidato

### ‚ùå STOP Proyecto Si:
- <70% precision en queries b√°sicas
- B√∫squedas retornan chunks irrelevantes consistentemente
- Problemas t√©cnicos irresolubles con vector search

**Si precision <80% ‚Üí Ajustar chunking strategy o considerar hybrid search**

---

# SEMANA 2: Backend de Consultas

## D√≠a 1: OpenAI Chat Integration
**Objetivos**: Convex + OpenAI funcionando end-to-end  
**Tiempo estimado**: 6 horas  

### Tareas Espec√≠ficas
1. **Crear `convex/lib/openai.ts`**
   ```typescript
   import OpenAI from "openai";
   
   const openai = new OpenAI({
     apiKey: process.env.OPENAI_API_KEY,
   });
   
   export async function generateChatResponse(
     query: string,
     context: string[]
   ): Promise<string> {
     const prompt = buildPrompt(query, context);
     
     const response = await openai.chat.completions.create({
       model: "gpt-4o-mini",
       messages: [{ role: "user", content: prompt }],
       temperature: 0.3,
       max_tokens: 1000,
     });
     
     return response.choices[0].message.content || "";
   }
   ```

2. **Crear `convex/aiChat.ts`**
   ```typescript
   import { action } from "./_generated/server";
   import { v } from "convex/values";
   import { vectorSearch } from "./queries";
   import { generateChatResponse } from "./lib/openai";
   
   export const chatWithDocs = action({
     args: { query: v.string() },
     handler: async (ctx, args) => {
       // 1. Vector search para encontrar contexto
       const searchResults = await ctx.runQuery(
         "queries:vectorSearch",
         { searchText: args.query, limit: 5 }
       );
       
       // 2. Assemblar contexto
       const context = searchResults.map(r => r.content);
       
       // 3. Generar respuesta con OpenAI
       const response = await generateChatResponse(args.query, context);
       
       // 4. Log conversation
       await ctx.runMutation("mutations:logConversation", {
         query: args.query,
         response,
         sources: searchResults.map(r => r._id),
       });
       
       return { response, sources: searchResults };
     },
   });
   ```

3. **Implementar context assembly**
   - Top 5 chunks m√°s relevantes
   - M√°ximo 3000 tokens de contexto
   - Metadata de sources para citaci√≥n

4. **Test consulta completa**
   ```bash
   # Desde Convex dashboard
   > ctx.runAction("aiChat:chatWithDocs", { query: "¬øQu√© propone Kast sobre pensiones?" })
   ```

### ‚úÖ Checkpoint
- ‚úÖ Query ‚Üí search ‚Üí context ‚Üí OpenAI funciona end-to-end
- ‚úÖ Respuesta coherente y relevante
- ‚úÖ Sources correctamente identificados
- ‚úÖ Response time <5s

---

## D√≠a 2: Prompt Engineering Optimization
**Objetivos**: Respuestas precisas y bien citadas  
**Tiempo estimado**: 6 horas  

### Tareas Espec√≠ficas
1. **Implementar prompt del PDR**
   ```typescript
   function buildPrompt(query: string, context: string[]): string {
     return `
   Eres un analista pol√≠tico chileno experto. 
   Responde SOLO bas√°ndote en el contexto proporcionado de programas presidenciales.
   Si no tienes informaci√≥n espec√≠fica, di "No tengo informaci√≥n sobre eso en los programas analizados".
   
   CONTEXTO DE PROGRAMAS PRESIDENCIALES:
   ${context.map((chunk, i) => `[${i+1}] ${chunk}`).join('\n\n')}
   
   CONSULTA: ${query}
   
   INSTRUCCIONES:
   1. Respuesta clara y concisa
   2. Cita fuentes espec√≠ficas usando [1], [2], etc.
   3. Si es comparaci√≥n, usa estructura organizada
   4. No inventes informaci√≥n que no est√© en el contexto
   `;
   }
   ```

2. **Testing con 30+ consultas variadas**
   - 10 consultas espec√≠ficas por candidato
   - 10 consultas comparativas
   - 10 consultas tem√°ticas generales

3. **Iteraci√≥n de prompts para reducir alucinaciones**
   - A/B testing de diferentes approaches
   - M√©tricas de hallucination rate
   - Optimizaci√≥n de citation format

4. **Implementar confidence scoring**
   ```typescript
   interface ChatResponse {
     response: string;
     confidence: number; // 0.0 - 1.0
     sources: Source[];
     hasInsufficientContext: boolean;
   }
   ```

### ‚úÖ Checkpoint
- ‚úÖ >85% respuestas √∫tiles en test set
- ‚úÖ <10% hallucination rate
- ‚úÖ Citations consistentes y precisas
- ‚úÖ Respuestas apropiadas para "no tengo informaci√≥n"

---

## D√≠a 3: Multi-Candidate Comparison Logic
**Objetivos**: Comparaciones estructuradas funcionando  
**Tiempo estimado**: 6 horas  

### Tareas Espec√≠ficas
1. **Parallel search function**
   ```typescript
   export const compareÂÄôÈÄâ‰∫∫ = action({
     args: { 
       query: v.string(),
       candidates: v.array(v.string())
     },
     handler: async (ctx, args) => {
       // B√∫squedas paralelas por candidato
       const searchPromises = args.candidates.map(candidate =>
         ctx.runQuery("queries:vectorSearch", {
           searchText: args.query,
           candidate,
           limit: 3
         })
       );
       
       const results = await Promise.all(searchPromises);
       // ... logic para comparative analysis
     }
   });
   ```

2. **Context assembly para comparaciones**
   - Balancear contexto entre candidatos
   - Evitar bias por cantidad de contenido
   - Structured output template

3. **Prompt para comparaciones**
   ```
   Compara las propuestas de los candidatos bas√°ndote en el contexto.
   
   Formato de respuesta:
   
   **[Candidato 1]:**
   - [propuesta espec√≠fica]
   
   **[Candidato 2]:**  
   - [propuesta espec√≠fica]
   
   **Principales diferencias:**
   - [an√°lisis comparativo]
   ```

4. **Test con 10+ consultas comparativas**
   - "Compara pol√≠ticas de pensiones de Kast y Boric"
   - "Diferencias en propuestas econ√≥micas entre todos los candidatos"
   - "¬øQui√©n propone mejor pol√≠tica de salud?"

### ‚úÖ Checkpoint
- ‚úÖ Comparaciones coherentes con format estructurado
- ‚úÖ Balance equitativo entre candidatos
- ‚úÖ An√°lisis de diferencias preciso
- ‚úÖ No bias sistem√°tico

---

## D√≠a 4: Error Handling + Edge Cases
**Objetivos**: Sistema robusto para edge cases  
**Tiempo estimado**: 5 horas  

### Tareas Espec√≠ficas
1. **Handling para queries sin resultados**
   ```typescript
   if (searchResults.length === 0) {
     return {
       response: "No encontr√© informaci√≥n espec√≠fica sobre esa consulta en los programas presidenciales analizados.",
       confidence: 0.0,
       sources: [],
       hasInsufficientContext: true
     };
   }
   ```

2. **Rate limiting implementation**
   ```typescript
   // En Convex action
   const rateLimitKey = `user_${getUserId()}_${Date.now()}`;
   // Implementar rate limiting logic
   ```

3. **Input sanitization y validation**
   - Query length limits
   - Malicious input detection
   - Special character handling

4. **Error logging y monitoring**
   - Structured error logging
   - Performance metrics tracking
   - Failed query analysis

5. **Fallback responses**
   - Partial results cuando contexto insuficiente
   - Graceful degradation cuando OpenAI API falla
   - Cache de respuestas populares

### ‚úÖ Checkpoint
- ‚úÖ Sistema maneja gracefully todos los edge cases
- ‚úÖ Error messages user-friendly
- ‚úÖ No crashes con inputs inesperados
- ‚úÖ Logging comprehensivo para debugging

---

## D√≠a 5: Performance + Cost Optimization
**Objetivos**: Sistema optimizado para producci√≥n  
**Tiempo estimado**: 5 horas  

### Tareas Espec√≠ficas
1. **Caching layer para queries similares**
   ```typescript
   const cacheKey = generateCacheKey(query);
   const cached = await getCachedResponse(cacheKey);
   if (cached && !isExpired(cached)) {
     return cached.response;
   }
   ```

2. **Token usage optimization**
   - Context compression para queries similares
   - Smart chunking para reduce token count
   - Batch processing donde sea posible

3. **Response time optimization**
   - Parallel processing donde sea posible
   - Connection pooling para OpenAI
   - Database query optimization

4. **Cost monitoring implementation**
   ```typescript
   interface UsageMetrics {
     tokensUsed: number;
     apiCalls: number;
     estimatedCost: number;
     timestamp: number;
   }
   ```

5. **Load testing con 100+ queries**
   - Concurrent users simulation  
   - Performance under load
   - Memory usage monitoring

### ‚úÖ Checkpoint
- ‚úÖ <$0.05 per query average cost
- ‚úÖ <3s response time p95
- ‚úÖ Sistema estable bajo load
- ‚úÖ Cost monitoring activo

---

# SEMANA 3: Frontend con assistant-ui

## D√≠a 1: Next.js + assistant-ui Setup
**Objetivos**: Chat interface b√°sico funcionando  
**Tiempo estimado**: 6 horas  

### Tareas Espec√≠ficas
1. **Install assistant-ui dependencies**
   ```bash
   npm install @assistant-ui/react ai lucide-react
   npm install @radix-ui/react-avatar @radix-ui/react-button
   ```

2. **Setup assistant-ui provider en `app/layout.tsx`**
   ```tsx
   import { AssistantRuntimeProvider } from "@assistant-ui/react";
   
   export default function RootLayout({
     children,
   }: {
     children: React.ReactNode;
   }) {
     return (
       <html lang="es">
         <body>
           <AssistantRuntimeProvider>
             {children}
           </AssistantRuntimeProvider>
         </body>
       </html>
     );
   }
   ```

3. **Crear `components/ChatInterface.tsx`**
   ```tsx
   import { Thread } from "@assistant-ui/react";
   import { useConvex } from "convex/react";
   
   export function ChatInterface() {
     const convex = useConvex();
     
     const handleMessage = async (message: string) => {
       return await convex.action("aiChat:chatWithDocs", { query: message });
     };
     
     return (
       <div className="h-screen flex flex-col">
         <Thread 
           onMessage={handleMessage}
           placeholder="Pregunta sobre los programas presidenciales..."
         />
       </div>
     );
   }
   ```

4. **Integraci√≥n con Convex en `app/page.tsx`**
   ```tsx
   import { ConvexProvider } from "convex/react";
   import { ChatInterface } from "@/components/ChatInterface";
   
   export default function Home() {
     return (
       <ConvexProvider url={process.env.NEXT_PUBLIC_CONVEX_URL!}>
         <ChatInterface />
       </ConvexProvider>
     );
   }
   ```

5. **Test mensaje b√°sico end-to-end**
   ```bash
   npm run dev
   # Enviar mensaje de prueba en la interfaz
   ```

### ‚úÖ Checkpoint
- ‚úÖ Chat interface se renderiza correctamente
- ‚úÖ Mensajes se env√≠an a Convex
- ‚úÖ Respuestas aparecen en el chat
- ‚úÖ No errores de console

---

## D√≠a 2: UI/UX Polish
**Objetivos**: Interface profesional y user-friendly  
**Tiempo estimado**: 6 horas  

### Tareas Espec√≠ficas
1. **Setup shadcn/ui**
   ```bash
   npx shadcn-ui@latest init
   npx shadcn-ui@latest add button input card avatar
   ```

2. **Styling responsive para mobile/desktop**
   ```tsx
   // Responsive design con Tailwind
   <div className="h-screen max-w-4xl mx-auto p-4 md:p-6">
     {/* Mobile-first approach */}
   </div>
   ```

3. **Loading states y typing indicators**
   ```tsx
   const [isTyping, setIsTyping] = useState(false);
   
   {isTyping && (
     <div className="flex items-center space-x-2">
       <div className="animate-pulse">Escribiendo...</div>
     </div>
   )}
   ```

4. **Message history y persistence**
   - Local storage para conversation history
   - Scroll to bottom en nuevos mensajes
   - Message timestamps

5. **Error states user-friendly**
   ```tsx
   {error && (
     <div className="bg-red-50 border border-red-200 rounded-lg p-4">
       <p className="text-red-800">
         Lo siento, hubo un error. Por favor intenta de nuevo.
       </p>
     </div>
   )}
   ```

### ‚úÖ Checkpoint
- ‚úÖ Interface pulida y profesional
- ‚úÖ Responsive design funciona en mobile/desktop
- ‚úÖ Loading states claros
- ‚úÖ Manejo de errores user-friendly

---

## D√≠a 3: Advanced Chat Features
**Objetivos**: Features avanzadas de chat  
**Tiempo estimado**: 7 horas  

### Tareas Espec√≠ficas
1. **Markdown rendering para respuestas**
   ```bash
   npm install react-markdown remark-gfm
   ```
   
   ```tsx
   import ReactMarkdown from 'react-markdown';
   
   <ReactMarkdown 
     remarkPlugins={[remarkGfm]}
     className="prose prose-sm max-w-none"
   >
     {message.content}
   </ReactMarkdown>
   ```

2. **Source citations clickable**
   ```tsx
   interface SourceCitation {
     id: string;
     candidate: string;
     section: string;
     page: number;
   }
   
   function CitationBadge({ source }: { source: SourceCitation }) {
     return (
       <button 
         className="inline-flex items-center px-2 py-1 rounded-full text-xs bg-blue-100 text-blue-800 hover:bg-blue-200"
         onClick={() => showSourceDetails(source)}
       >
         {source.candidate} - p.{source.page}
       </button>
     );
   }
   ```

3. **Query suggestions/autocomplete**
   ```tsx
   const suggestions = [
     "¬øQu√© propone Boric sobre educaci√≥n?",
     "Compara las pol√≠ticas econ√≥micas de Kast y Sichel",
     "¬øCu√°l es la posici√≥n de Provoste sobre pensiones?",
   ];
   ```

4. **Chat history management**
   - Persistent conversations en localStorage
   - Clear conversation button
   - Export conversation functionality

5. **Export conversation feature**
   ```tsx
   const exportConversation = () => {
     const data = JSON.stringify(messages, null, 2);
     const blob = new Blob([data], { type: 'application/json' });
     const url = URL.createObjectURL(blob);
     const a = document.createElement('a');
     a.href = url;
     a.download = 'conversacion-programas-presidenciales.json';
     a.click();
   };
   ```

### ‚úÖ Checkpoint
- ‚úÖ Markdown rendering funciona perfectamente
- ‚úÖ Source citations son clickables e informativas
- ‚úÖ Suggestions mejoran UX
- ‚úÖ Chat experience comparable a ChatGPT

---

## D√≠a 4: Testing + Bug Fixes
**Objetivos**: Sistema estable sin bugs cr√≠ticos  
**Tiempo estimado**: 6 horas  

### Tareas Espec√≠ficas
1. **Cross-browser testing**
   - Chrome (latest)
   - Firefox (latest)
   - Safari (latest)
   - Edge (latest)

2. **Mobile testing**
   - iOS Safari
   - Android Chrome
   - Responsive breakpoints
   - Touch interactions

3. **Performance testing del frontend**
   ```bash
   npm run build
   npm run start
   # Test con Lighthouse
   ```

4. **Bug fixing**
   - UI glitches
   - Performance issues
   - Accessibility basic compliance

5. **Accessibility improvements**
   - Keyboard navigation
   - Screen reader support
   - Color contrast
   - Focus indicators

### ‚úÖ Checkpoint
- ‚úÖ Zero critical bugs
- ‚úÖ Mobile-friendly experience
- ‚úÖ Performance score >90 en Lighthouse
- ‚úÖ Basic accessibility compliance

---

## D√≠a 5: Integration Testing
**Objetivos**: End-to-end system validation  
**Tiempo estimado**: 5 horas  

### Tareas Espec√≠ficas
1. **Full integration testing**
   - Test complete user journeys
   - 50+ real queries de diferentes tipos
   - Edge cases validation

2. **Performance testing con m√∫ltiples usuarios**
   - Concurrent user simulation
   - System stability under load
   - Response time consistency

3. **Final UI/UX improvements**
   - Based on testing feedback
   - Polish remaining rough edges
   - Optimize for target user (incluye abuelas)

4. **Pre-production checklist**
   - [ ] All features working
   - [ ] No critical bugs
   - [ ] Performance acceptable
   - [ ] Mobile experience good
   - [ ] Error handling complete

### ‚úÖ Checkpoint
- ‚úÖ Sistema listo para user testing
- ‚úÖ All integration tests pass
- ‚úÖ Performance meets targets
- ‚úÖ Ready for Semana 4

---

# SEMANA 4: Testing y Refinamiento

## D√≠a 1-2: User Testing
**Objetivos**: Feedback real de usuarios target  
**Tiempo estimado**: 12 horas (2 d√≠as)  

### Tareas Espec√≠ficas
1. **Reclutar 10+ testers**
   - 2-3 personas mayores (60+)
   - 3-4 adultos medios (30-60)  
   - 2-3 j√≥venes (18-30)
   - 2-3 personas con diferentes niveles de tech literacy

2. **Preparar testing protocol**
   ```
   Sesi√≥n de 30 minutos:
   - 5 min: Introducci√≥n y contexto
   - 20 min: Testing libre + tareas espec√≠ficas
   - 5 min: Feedback y Q&A
   
   Tareas espec√≠ficas:
   1. "Busca qu√© propone tu candidato favorito sobre pensiones"
   2. "Compara las pol√≠ticas de salud de 2 candidatos"
   3. "Encuentra propuestas sobre medio ambiente"
   ```

3. **Documentar feedback sistem√°ticamente**
   ```
   Por cada tester:
   - Demographic info
   - Task completion rate
   - Time to complete tasks
   - Satisfaction score (1-5)
   - Specific pain points
   - Feature requests
   - Quote memorable
   ```

4. **Testing sessions execution**
   - Record sessions (con permiso)
   - Take detailed notes
   - Observe behavior patterns
   - Ask follow-up questions

5. **An√°lisis de resultados**
   - Categorizar feedback por tema
   - Identificar pain points m√°s comunes
   - Prioritizar issues por impacto

### ‚úÖ Checkpoint
- ‚úÖ 10+ testing sessions completed
- ‚úÖ Feedback score >4/5 average
- ‚úÖ >60% task completion rate
- ‚úÖ Issues prioritizados por impacto

---

## D√≠a 3-4: Refinement Based on Feedback
**Objetivos**: Implementar mejoras cr√≠ticas  
**Tiempo estimado**: 12 horas (2 d√≠as)  

### Tareas Espec√≠ficas
1. **Bug fixes de issues cr√≠ticos**
   - Crashes o errores que impiden uso
   - Performance issues significativos
   - UX blockers principales

2. **UX improvements m√°s impactantes**
   T√≠picos improvements esperados:
   - Query suggestions m√°s relevantes
   - Better onboarding/instrucciones iniciales
   - Clearer source citations
   - Faster response times
   - Better mobile experience

3. **Prompt tuning basado en feedback**
   - Ajustar tone para ser m√°s accesible
   - Mejorar explanations para no-expertos
   - Optimizar format de respuestas

4. **Performance optimization**
   - Based on user-reported slow responses
   - Optimize heavy operations
   - Improve caching

5. **Final testing post-improvements**
   - Test con subset de original testers
   - Validate improvements work
   - No regressions introduced

### ‚úÖ Checkpoint
- ‚úÖ Issues cr√≠ticos resueltos
- ‚úÖ UX improvements implemented
- ‚úÖ Feedback score increased to >4.2/5
- ‚úÖ No regressions from changes

---

## D√≠a 5: Production Deploy
**Objetivos**: Sistema live y monitoreado  
**Tiempo estimado**: 6 horas  

### Tareas Espec√≠ficas
1. **Vercel deployment setup**
   ```bash
   # Install Vercel CLI
   npm i -g vercel
   
   # Deploy
   vercel --prod
   ```

2. **Environment variables configuration**
   ```bash
   # En Vercel dashboard
   OPENAI_API_KEY=your_key
   CONVEX_URL=your_convex_url
   NEXT_PUBLIC_CONVEX_URL=your_public_convex_url
   ```

3. **Domain setup (opcional)**
   - Custom domain si disponible
   - SSL certificate
   - DNS configuration

4. **Monitoring y alerting setup**
   ```typescript
   // Basic monitoring
   const logUsage = async () => {
     await ctx.db.insert("usage_logs", {
       timestamp: Date.now(),
       queries_per_day: count,
       errors_per_day: errorCount,
     });
   };
   ```

5. **Final smoke testing en production**
   - Test all major features
   - Verify performance
   - Check error handling
   - Monitor initial usage

### ‚úÖ Checkpoint FINAL
- ‚úÖ URL p√∫blica funcionando
- ‚úÖ All features work en production
- ‚úÖ Performance acceptable
- ‚úÖ Monitoring activo
- ‚úÖ **MVP COMPLETO Y LIVE** üéâ

---

## Scripts de Validaci√≥n

### `tests/validate_week1.sh`
```bash
#!/bin/bash

echo "üîç Validating Week 1: PDF Processing..."

# Test PDF extraction
echo "Testing PDF extraction..."
cd scripts
python test_extraction.py
if [ $? -ne 0 ]; then
    echo "‚ùå PDF extraction failed"
    exit 1
fi

# Test embeddings generation
echo "Testing embeddings..."
python test_embeddings.py
if [ $? -ne 0 ]; then
    echo "‚ùå Embeddings failed"
    exit 1
fi

# Test Convex upload
echo "Testing Convex upload..."
python test_upload.py
if [ $? -ne 0 ]; then
    echo "‚ùå Convex upload failed"
    exit 1
fi

# Test vector search
echo "Testing vector search..."
npx convex run queries:vectorSearch '{"searchText": "pensiones", "limit": 5}'
if [ $? -ne 0 ]; then
    echo "‚ùå Vector search failed"
    exit 1
fi

echo "‚úÖ Week 1 validation complete - PDF processing working!"
```

### `tests/validate_week2.sh`
```bash
#!/bin/bash

echo "üîç Validating Week 2: Query System..."

# Test basic chat
echo "Testing basic chat functionality..."
npx convex run aiChat:chatWithDocs '{"query": "¬øQu√© propone Boric sobre educaci√≥n?"}'
if [ $? -ne 0 ]; then
    echo "‚ùå Chat functionality failed"
    exit 1
fi

# Test comparison queries
echo "Testing comparison queries..."
npx convex run aiChat:chatWithDocs '{"query": "Compara pol√≠ticas econ√≥micas de Kast y Boric"}'
if [ $? -ne 0 ]; then
    echo "‚ùå Comparison queries failed"
    exit 1
fi

# Test performance
echo "Testing response times..."
time npx convex run aiChat:chatWithDocs '{"query": "pol√≠ticas de salud"}'

echo "‚úÖ Week 2 validation complete - Query system working!"
```

### `tests/health_check.sh`
```bash
#!/bin/bash

echo "üîç Production Health Check..."

# Check if site is accessible
curl -f https://your-domain.vercel.app/
if [ $? -ne 0 ]; then
    echo "‚ùå Site not accessible"
    exit 1
fi

# Check API health
curl -f https://your-domain.vercel.app/api/health
if [ $? -ne 0 ]; then
    echo "‚ùå API health check failed"
    exit 1
fi

# Run basic E2E test
npm run test:e2e
if [ $? -ne 0 ]; then
    echo "‚ùå E2E tests failed"
    exit 1
fi

echo "‚úÖ Production health check passed!"
```

---

## Checkpoints Cr√≠ticos y Criterios

### Week 1 Go/No-Go Decision Points

**Checkpoint 1.1 - D√≠a 1 (Setup Foundation)**
- ‚úÖ **Go criteria**: Convex deployed, schema active, vector index created
- ‚ùå **Stop criteria**: Schema deployment fails, connection issues
- **If Stop**: Debug Convex setup, check API keys, verify internet connection

**Checkpoint 1.2 - D√≠a 2 (PDF Processing)**  
- ‚úÖ **Go criteria**: >80% text extraction accuracy, coherent chunks generated
- ‚ùå **Stop criteria**: <50% extraction accuracy, PDFs unreadable
- **If Stop**: Switch to OCR with Tesseract, manually clean PDFs, or reduce PDF scope

**Checkpoint 1.3 - D√≠a 4 (Scale to All PDFs)**
- ‚úÖ **Go criteria**: ‚â•5/7 PDFs processed, 500+ chunks total, vector search works
- ‚ùå **Stop criteria**: <5 PDFs processed, <300 chunks, systematic failures
- **If Stop**: Focus on 5 best PDFs, manual processing for problematic ones

**Checkpoint 1.4 - D√≠a 5 (Query Validation)**
- ‚úÖ **Go criteria**: >80% query precision, multi-candidate search works
- ‚ùå **STOP PROJECT criteria**: <70% precision, systematic search failures
- **If Stop**: Major re-architecture needed, consider different approach

### Week 2 Quality Gates

**Checkpoint 2.1 - D√≠a 2 (Prompt Optimization)**
- ‚úÖ **Go criteria**: >85% useful responses, <10% hallucination rate
- ‚ùå **Stop criteria**: >30% hallucination rate, responses consistently poor
- **If Stop**: Major prompt re-engineering, different AI model, or context strategy

**Checkpoint 2.2 - D√≠a 5 (Performance)**
- ‚úÖ **Go criteria**: <3s response time, <$0.05 per query
- ‚ùå **Stop criteria**: >10s responses, >$0.20 per query
- **If Stop**: Optimize context size, implement caching, different AI model

### Week 3 Integration Gates

**Checkpoint 3.1 - D√≠a 2 (UI/UX)**
- ‚úÖ **Go criteria**: Professional appearance, mobile-friendly
- ‚ùå **Stop criteria**: Broken UI, unusable on mobile
- **If Stop**: Simplify UI, focus on core functionality

**Checkpoint 3.2 - D√≠a 5 (Integration)**
- ‚úÖ **Go criteria**: End-to-end system works, ready for user testing
- ‚ùå **Stop criteria**: Major integration issues, system unreliable
- **If Stop**: Debug integration, focus on core path

### Week 4 Launch Gates

**Checkpoint 4.1 - D√≠a 2 (User Testing)**
- ‚úÖ **Go criteria**: >4/5 satisfaction, >60% task completion
- ‚ùå **Stop criteria**: <3/5 satisfaction, <30% completion
- **If Stop**: Major UX redesign needed, extend timeline

**Final Go-Live Decision**
- ‚úÖ **Launch criteria**: All major features work, no critical bugs, user feedback >4/5
- ‚ùå **Delay launch**: Critical bugs, poor user feedback, system unreliable

---

## Contingency Plans Detallados

### Contingencia A: PDFs No Procesables (Probabilidad: Media, Impacto: Alto)

**Trigger**: >2 de 7 PDFs no se procesan correctamente

**Immediate Actions**:
1. **Switch a OCR**: Implementar Tesseract para PDFs problem√°ticos
   ```bash
   pip install pytesseract Pillow pdf2image
   ```
2. **Manual cleaning**: Convertir PDFs problem√°ticos a texto manualmente
3. **Reduce scope**: Proceder con 5 PDFs m√≠nimos viables
4. **Timeline adjustment**: +3 d√≠as para resoluci√≥n

**Success criteria para continuar**: Al menos 5 PDFs procesados con >70% accuracy

**Escalation**: Si <5 PDFs procesables ‚Üí considerar cambio radical de approach

---

### Contingencia B: Vector Search Impreciso (Probabilidad: Media, Impacto: Alto)

**Trigger**: <80% relevancia en queries de testing

**Immediate Actions**:
1. **Chunking adjustment**:
   - Reduce chunk size de 1000 a 800 tokens
   - Increase overlap de 200 a 300 tokens
   - Add m√°s contexto en metadata
   
2. **Reranking implementation**:
   ```python
   def rerank_results(query, results):
       # Implementar semantic reranking
       return sorted_results
   ```

3. **Hybrid search**: Combinar vector + keyword search

4. **Metadata enhancement**: M√°s keywords y context tags

**Success criteria**: >85% relevancia despu√©s de ajustes

**Escalation**: Si <75% despu√©s de ajustes ‚Üí considerar different embedding model

---

### Contingencia C: OpenAI Costs Excesivos (Probabilidad: Baja, Impacto: Medio)

**Trigger**: Costos proyectados >$200 para MVP

**Immediate Actions**:
1. **Aggressive caching**:
   ```typescript
   const cacheResponse = (query: string, response: string, ttl: number) => {
     // 24 hour cache for identical queries
   };
   ```

2. **Context optimization**:
   - Reduce context window de 3000 a 2000 tokens
   - Better chunk selection algorithm
   - Compress redundant information

3. **Rate limiting**:
   - 10 queries per user per hour
   - Queue system for high usage

4. **Alternative models**: Test con modelos m√°s baratos

**Success criteria**: <$50 projected monthly costs

---

### Contingencia D: assistant-ui Integration Issues (Probabilidad: Baja, Impacto: Medio)

**Trigger**: Problemas irresolubles con assistant-ui

**Immediate Actions**:
1. **Custom chat UI**: Build b√°sico con shadcn/ui
   ```tsx
   // Simple chat implementation
   const SimpleChatUI = () => {
     // Basic message sending/receiving
   };
   ```

2. **Focus en funcionalidad core**: Priorizar chat functionality sobre advanced features

3. **Timeline adjustment**: +2 d√≠as para custom implementation

**Success criteria**: Basic chat working, acceptable UX

---

### Contingencia E: Performance Issues en Producci√≥n (Probabilidad: Media, Impacto: Medio)

**Trigger**: Response times >10s o crashes frecuentes

**Immediate Actions**:
1. **Horizontal scaling**: Multiple Convex deployments
2. **Caching layer**: Redis o similar
3. **Connection pooling**: Optimize database connections
4. **Query optimization**: Review y optimize slow queries

**Success criteria**: <5s response times, >99% uptime

---

## Comandos de Setup Completos

### Initial Project Setup (Copy-Paste Ready)

```bash
# 1. Create Next.js project
npx create-next-app@latest chatbot-politico --typescript --tailwind --app
cd chatbot-politico

# 2. Setup Convex
npx convex init
# Follow the setup wizard, select your team

# 3. Install dependencies
npm install @assistant-ui/react ai lucide-react
npm install @radix-ui/react-avatar @radix-ui/react-button
npm install react-markdown remark-gfm

# 4. Setup shadcn/ui
npx shadcn-ui@latest init
npx shadcn-ui@latest add button input card avatar

# 5. Setup Python environment
cd scripts
python -m venv venv

# Windows
venv\Scripts\activate

# Mac/Linux  
source venv/bin/activate

# Install Python dependencies
pip install -r requirements.txt

# 6. Create environment file
cd ..
cp .env.local.example .env.local
# Edit .env.local with your API keys

# 7. Setup development
npm run dev          # Terminal 1: Next.js
npx convex dev       # Terminal 2: Convex

echo "‚úÖ Initial setup complete!"
```

### Development Workflow Commands

```bash
# Start development environment
npm run dev          # Next.js development server
npx convex dev       # Convex development server (separate terminal)

# Process PDFs (Week 1)
cd scripts
python process_pdfs.py --single kast_programa.pdf  # Test with one
python process_pdfs.py --batch                     # Process all

# Deploy backend changes
npx convex deploy

# Run validations
bash tests/validate_week1.sh
bash tests/validate_week2.sh

# Production build
npm run build
npm run start

# Production deploy
vercel --prod

# Health checks
bash tests/health_check.sh
curl -f https://your-app.vercel.app/api/health
```

### Debugging Commands

```bash
# Check Convex logs
npx convex logs

# Test individual functions
npx convex run queries:vectorSearch '{"searchText": "pensiones"}'
npx convex run aiChat:chatWithDocs '{"query": "test"}'

# Database inspection
npx convex dashboard  # Opens web dashboard

# Check embeddings
python scripts/test_embeddings.py

# Performance profiling
npm run build && npm run start
# Test with Lighthouse
```

### Emergency Recovery Commands

```bash
# Reset Convex schema (nuclear option)
npx convex schema --clear  # ‚ö†Ô∏è Deletes all data

# Redeploy everything
npx convex deploy --yes

# Clear caches
rm -rf .next node_modules
npm install
npm run dev

# Backup data
npx convex export backup.jsonl

# Restore data
npx convex import backup.jsonl
```

---

## Timeline y Dependencias

### Dependencias Cr√≠ticas

```mermaid
graph TD
    A[Setup Convex] --> B[Schema Deploy]
    B --> C[PDF Processing]
    C --> D[Vector Search Test]
    D --> E{Go/No-Go}
    E -->|Go| F[OpenAI Integration]
    E -->|Stop| G[Fix Issues]
    F --> H[Frontend Setup]
    H --> I[User Testing]
    I --> J[Production Deploy]
```

### Risk Mitigation Timeline

**Week 1**: Front-load highest risk (PDF processing)
- Days 1-2: Infrastructure setup  
- Days 3-4: PDF processing validation
- Day 5: **Critical Go/No-Go decision**

**Week 2**: Build on validated foundation
- Known working PDF processing
- Focus on query quality
- Performance optimization

**Week 3**: UI implementation
- Lower technical risk
- Focus on UX
- Integration testing

**Week 4**: Validation and launch
- User feedback integration
- Final polish
- Production deployment

### Buffer Time Allocation

- **Week 1**: 20% buffer (highest risk)
- **Week 2**: 15% buffer  
- **Week 3**: 10% buffer
- **Week 4**: 5% buffer + entire day 5 as final buffer

---

## Resources y Referencias

### Documentaci√≥n Oficial
- [Convex Documentation](https://docs.convex.dev/)
- [assistant-ui Documentation](https://ui.assistant.dev/)
- [Next.js 14 Documentation](https://nextjs.org/docs)
- [OpenAI API Reference](https://platform.openai.com/docs)
- [shadcn/ui Components](https://ui.shadcn.com/)

### Tools y Utilidades
- [Convex Dashboard](https://dashboard.convex.dev/)
- [Vercel Dashboard](https://vercel.com/dashboard)
- [OpenAI Usage Dashboard](https://platform.openai.com/usage)

### Python Libraries
- [pymupdf4llm Documentation](https://github.com/pymupdf/RAG)
- [OpenAI Python Client](https://github.com/openai/openai-python)

### Testing Tools
- [Lighthouse CLI](https://developers.google.com/web/tools/lighthouse)
- [Playwright](https://playwright.dev/) (for E2E testing)

### Deployment Platforms
- [Vercel Deployment Guide](https://vercel.com/docs)
- [Custom Domain Setup](https://vercel.com/docs/concepts/projects/custom-domains)

---

## Success Metrics Tracking

### Technical Metrics (Automated)
```typescript
interface TechnicalMetrics {
  // Performance
  averageResponseTime: number;    // Target: <3s
  p95ResponseTime: number;        // Target: <5s
  uptime: number;                 // Target: >99%
  
  // Quality  
  querySuccessRate: number;       // Target: >90%
  hallucination_rate: number;     // Target: <10%
  
  // Cost
  costPerQuery: number;           // Target: <$0.05
  monthlyAPISpend: number;        // Target: <$50
  
  // Usage
  dailyActiveUsers: number;
  queriesPerUser: number;         // Target: >2 (retention indicator)
}
```

### User Experience Metrics (Manual Tracking)
```typescript
interface UXMetrics {
  userSatisfactionScore: number;  // Target: >4/5
  taskCompletionRate: number;     // Target: >80%
  timeToFirstAnswer: number;      // Target: <30s
  mobileUsabilityScore: number;   // Target: >4/5
  seniorUserFriendly: boolean;    // Target: true
}
```

### Business Metrics
```typescript
interface BusinessMetrics {
  totalUniqueUsers: number;
  userRetention24h: number;       // Target: >60%
  averageSessionLength: number;   // Target: >5 minutes
  organicShareRate: number;       // People sharing the tool
  feedbackScore: number;          // Target: >4.2/5
}
```

---

## Post-Launch Roadmap (Fuera de Scope del MVP)

### Version 1.1 (Post-MVP, +2 semanas)
- User authentication y session persistence
- Conversation history per user
- Analytics dashboard para usage insights
- More sophisticated caching
- A/B testing framework para prompts

### Version 1.2 (+1 mes)
- Support para m√°s elecciones (municipales, parlamentarias)
- API p√∫blica para developers
- Webhook integration para updates
- Advanced search filters
- PDF upload por usuarios

### Version 2.0 (+3 meses)
- Multi-language support
- Voice interface
- Mobile app (React Native)
- Real-time collaboration features
- AI-powered political analysis reports

---

## Conclusi√≥n del Plan

### ‚úÖ Plan Validation Checklist

- [x] **Timeline realista**: 4 semanas con buffers apropiados
- [x] **Riesgos identificados**: PDF processing como mayor riesgo, front-loaded
- [x] **Stack validado**: Technolog√≠a probada y production-ready
- [x] **Scope claro**: MVP enfocado sin feature creep
- [x] **Checkpoints definidos**: Go/No-Go decisions claros
- [x] **Contingencies prepared**: Plan B para cada riesgo mayor
- [x] **Success metrics**: Objetivos medibles y realistas

### üéØ Critical Success Factors

1. **Week 1 success**: Si Week 1 funciona bien, resto tiene alta probabilidad de √©xito
2. **User-focused approach**: Dise√±o pensado para usuarios reales (incluye abuelas)
3. **Iterative validation**: Checkpoint frecuentes previenen work en direcci√≥n incorrecta  
4. **Performance consciousness**: Optimizado desde el inicio, no como afterthought
5. **Evidence-based decisions**: Todas las decisiones basadas en testing real

### üöÄ Ready to Execute

**Next immediate action**: Ejecutar D√≠a 1 setup commands y validar primer checkpoint.

**Este plan es ejecutable, realista, y tiene alta probabilidad de √©xito. ¬°Proceder con implementaci√≥n!**

---

**Documento completo: Plan de Implementaci√≥n MVP - Chatbot Pol√≠tico**  
**Total p√°ginas**: ~50 p√°ginas de plan detallado  

**Status**: ‚úÖ **LISTO PARA EJECUTAR**